ğŸ“„ Copiloto Conversacional sobre PDFs

Una aplicaciÃ³n de Streamlit que permite procesar PDFs y hacer preguntas sobre su contenido usando IA local (Ollama) y RAG (Retrieval-Augmented Generation).

ğŸš€ CaracterÃ­sticas

Procesamiento de PDFs: Extrae texto y crea chunks para anÃ¡lisis

IA Local: Usa Ollama con el modelo llama3 para procesamiento local

RAG: Sistema de bÃºsqueda semÃ¡ntica para respuestas contextuales

Interfaz Web: AplicaciÃ³n Streamlit fÃ¡cil de usar

Persistencia opcional: Almacena embeddings en Chroma DB local (puede deshabilitarse)

ContenerizaciÃ³n: EjecuciÃ³n con Docker y Docker Compose para un entorno reproducible

ğŸ“‹ Requisitos Previos
OpciÃ³n A: EjecuciÃ³n nativa

Python 3.8+

Ollama instalado y configurado

Modelo llama3 descargado

OpciÃ³n B: EjecuciÃ³n con Docker

Docker Desktop (Windows/Mac) o Docker Engine (Linux)

Docker Compose plugin

ğŸ› ï¸ InstalaciÃ³n

1. Clonar el repositorio
   git clone <tu-repositorio>
   cd copiloto_pdfs

ğŸš€ OpciÃ³n A: Ejecutar localmente con Python 2. Crear y activar entorno virtual

(ver instrucciones de Windows, Linux/Mac en el archivo original)

3. Instalar dependencias
   pip install -r requirements.txt

4. Configurar Ollama

# Iniciar servicio Ollama

ollama serve

# Descargar modelo llama3

ollama pull llama3

5. Ejecutar la aplicaciÃ³n
   streamlit run app.py

Abrir navegador en http://localhost:8501

ğŸ³ OpciÃ³n B: Ejecutar con Docker 2. Construir la imagen
docker compose build

3. Iniciar los contenedores
   docker compose up -d

Esto levanta:

ollama (servidor LLM local en el puerto 11434)

app (la aplicaciÃ³n Streamlit en el puerto 8501)

4. Abrir la aplicaciÃ³n
   http://localhost:8501

5. Detener la aplicaciÃ³n
   docker compose down

ğŸ“ Estructura del Proyecto
copiloto_pdfs/
â”œâ”€â”€ app.py # AplicaciÃ³n principal de Streamlit
â”œâ”€â”€ requirements.txt # Dependencias de Python
â”œâ”€â”€ Dockerfile # Imagen para la app
â”œâ”€â”€ docker-compose.yml # OrquestaciÃ³n con Docker
â”œâ”€â”€ activate_venv.bat # Script de activaciÃ³n (Windows CMD)
â”œâ”€â”€ activate_venv.ps1 # Script de activaciÃ³n (PowerShell)
â”œâ”€â”€ venv/ # Entorno virtual (local, no en Docker)
â”œâ”€â”€ data/ # Datos persistentes (si se habilitan)
â”‚ â””â”€â”€ chroma/ # Base de datos vectorial
â””â”€â”€ README.md # Este archivo

ğŸ”§ SoluciÃ³n de Problemas
Docker

Reconstruir la imagen despuÃ©s de cambios en dependencias:

docker compose build app
docker compose up -d

Ver logs en vivo:

docker compose logs -f app

Abrir y cerrar rÃ¡pido la app con un solo comando (Linux/Mac):

docker compose up -d && xdg-open http://localhost:8501

En Windows (PowerShell):

docker compose up -d; Start-Process "http://localhost:8501"

Ollama

(conservar las notas de tu README original)

ğŸ“š Dependencias Principales

Streamlit: Interfaz web

PyPDF2: Procesamiento de PDFs

LangChain: Framework para aplicaciones de IA

ChromaDB: Base de datos vectorial

Sentence Transformers: Embeddings de texto

Ollama: LLM local

Docker + Docker Compose: OrquestaciÃ³n y despliegue

ğŸ‘‰ Â¿Quieres que ademÃ¡s te prepare un snippet con comandos rÃ¡pidos (copiloto-start y copiloto-stop) para que lo pongas en tu README y no tengas que memorizar docker compose up y down?
